{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Mean Encoding  (TS encoding, Target Encoding)  ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you’re doing supervised learning you often have to deal with categorical variables. That is, variables which don’t have a natural numerical representation. The problem is that most machine learning algorithms require the input data to be numerical. At some point or another a data science pipeline will require converting categorical variables to numerical variables.\n",
    "\n",
    "\n",
    "There are many ways to do so, but the most popularonce are:\n",
    "\n",
    "1. **Label encoding**: where you choose an arbitrary number for each category\n",
    "\n",
    "\n",
    "2. **One-hot encoding**: where you create one binary column per category\n",
    "\n",
    "\n",
    "3. **Vector representation**: a.k.a. **Entity encoding** (**word2vec**) where you find a low dimensional subspace that fits your data\n",
    "\n",
    "\n",
    "4. **Optimal binning**: where you rely on tree-learners such as LightGBM or CatBoost\n",
    "\n",
    "\n",
    "5. **Target encoding**: where you average the target value by category\n",
    "\n",
    "\n",
    "Each and every one of these method has it’s pros and cons, and it usually depends on your data and your requirements. If a variable has a lot of categories then a one-hot encoding scheme will produce many columns which can cause memory issues. In my experience relying on LightGBM/CatBoost is the best out-of-the-box method. Label encoding is useless and you should never use it. However if your categorical variable happens to be ordinal then you can and should represent it with increasing numbers (for example “cold” becomes 0, “mild” becomes 1, and “hot” becomes 2). word2vec and others such methods are cool and good but they require some fine-tuning and don’t always work out.\n",
    "\n",
    "Target encoding (TS encoding, mean encoding) is a fast way to get the most out of your categorical variables with little effort. The idea is quite simple:\n",
    "\n",
    "Say you have a categorical variable x and a target y.\n",
    "\n",
    "\n",
    "y can be binary,multinominal or continuous, it doesn’t matter.\n",
    "\n",
    "\n",
    "For each distinct (unique) element in x you’re going to compute the average of the corresponding values in y.\n",
    "\n",
    "\n",
    "Then you’re going to replace each x_i with the according mean. This is rather easy to do in Python and the pandas library.\n",
    "\n",
    "First let’s create some dummy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In a nutshell, it uses the target variable as the basis to generate the new encoded feature.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a look at an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table01](./images/table01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample dataset we can see a feature named `Jobs`, another feature named `Age` and a target variable which points to a binary classification problem with target variables `1` and `0`. Now, feature `Age` is all set since it’s already numerical but now we need to encode feature `Jobs`.\n",
    "\n",
    "The most obvious approach would be label encoding, where we would convert the values according to a mapping logic — an example is 1 for Doctor, 2 for Teacher, 3 for Engineer, 4 for Waiter and 5 for Driver. Thus the result would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table02](./images/table02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s nothing wrong with this approach really. However, if we look at the distribution of the feature, we see that it is completely random, no correlation whatsoever with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chart01](./images/chart01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which makes sense, right? There wasn’t any specific logic regarding the mapping we applied, we just gave each job a number and that was it. Now, is there another way we can encode this feature so that it’s not so random and maybe gives us some extra information about the target variable itself?\n",
    "\n",
    "Let’s try this: for each unique value of the categorical feature, let us encode it based on the ratio of occurrence of the positive class in the target variable (**mean of the targets for that categorical value**). The result would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![table03](./images/table03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? For example, let’s look at unique value “Doctor”. It has 4 occurrences of the target variable and 2 of those are the positive label — therefore, mean encoding would be 0.5 for value “Doctor”. Repeat the process or all unique values of the feature and you get the result.\n",
    "\n",
    "Now let’s look at the distribution of the feature once again and see the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chart02](./images/chart02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target classes seem way more separate — class 1 to the right, class 0 to the left — because there is a correlation between the feature value and the target class. **From a mathematical point of view, mean encoding represents a probability of your target variable, conditional on each value of the feature.** In a way, it embodies the target variable in its encoded value.\n",
    "\n",
    "To conclude, what **mean encoding** does is, it solves both the encoding task and also creates a feature that is more representative of the target variable — **essentially getting two fruits with one stone.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prons and Cons\n",
    "\n",
    "However, it’s not all roses. While mean encoding has shown to increase the quality of a classification model, it doesn’t go without its problems; the main one being the usual suspect, **overfitting.**\n",
    "\n",
    "The fact that we are encoding the feature based on target classes may lead to **data leakage**, rendering the feature biased. To solve this, mean encoding is usually used with some type of Regularization. Check [this solution](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36136#201638) on Kaggle as an example, where the author used an averaged cross-validation scheme.\n",
    "\n",
    "we might as well mention gradient boosting trees and how mean encoding is particularly useful with those. One of GBT’s downsides is its inability to handle high-cardinality categorical features, because trees have limited depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![graph01](./images/graph01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since mean encoding considerably decreases cardinality, as we’ve seen before, it becomes a great tool to use in order to reach a better loss with a shorter tree, and thus improving the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HINT:** measure the cardinality of the categorical features before and after applying mean encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Encoding  (TS encoding, Mean Encoding)  Done The Right Way\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target encoding is rather easy to do in Python and the pandas library, but doing it the right way gives lot mileage in accuracy improvement. Let me illustrate this with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x_0': ['a'] * 5 + ['b'] * 5,\n",
    "    'x_1': ['a'] * 9 + ['b'] * 1,\n",
    "    'y': [1, 1, 1, 1, 0, 1, 0, 0, 0, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  x_0 x_1  y\n",
       "0   a   a  1\n",
       "1   a   a  1\n",
       "2   a   a  1\n",
       "3   a   a  1\n",
       "4   a   a  0\n",
       "5   b   a  1\n",
       "6   b   a  0\n",
       "7   b   a  0\n",
       "8   b   a  0\n",
       "9   b   b  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by computing the means of the `x_0` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df.groupby('x_0')['y'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x_0\n",
       "a    0.8\n",
       "b    0.2\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then replace each value in x_0 with the matching mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_0 x_1  y\n",
       "0  0.8   a  1\n",
       "1  0.8   a  1\n",
       "2  0.8   a  1\n",
       "3  0.8   a  1\n",
       "4  0.8   a  0\n",
       "5  0.2   a  1\n",
       "6  0.2   a  0\n",
       "7  0.2   a  0\n",
       "8  0.2   a  0\n",
       "9  0.2   b  0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x_0'] = df['x_0'].map(means)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for `x_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_0       x_1  y\n",
       "0  0.8  0.555556  1\n",
       "1  0.8  0.555556  1\n",
       "2  0.8  0.555556  1\n",
       "3  0.8  0.555556  1\n",
       "4  0.8  0.555556  0\n",
       "5  0.2  0.555556  1\n",
       "6  0.2  0.555556  0\n",
       "7  0.2  0.555556  0\n",
       "8  0.2  0.555556  0\n",
       "9  0.2  0.000000  0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x_1'] = df['x_1'].map(df.groupby('x_1')['y'].mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target encoding is good because it picks up values that can explain the target. In this silly example value `a` of variable `x_0`has an average target value of 0.8.\n",
    "This can greatly help the machine learning classifications algorithms used downstream.\n",
    "\n",
    "The problem of target encoding has a name: **over-fitting**. Indeed relying on an average value isn’t always a good idea when the number of values used in the average is low. You’ve got to keep in mind that the dataset you’re training on is a sample of a larger set. This means that whatever artifacts you may find in the training set might not hold true when applied to another dataset (i.e. the test set).\n",
    "\n",
    "In the example, the value `d` of variable `x_1`is replaced with a 0 because it only appears once and the corresponding value of y is a 0. In this case we’re over-fitting because we don’t have enough values to be sure that 0 is in fact the mean value of `y` when `x_1`is equal to `d`.\n",
    "In other words only relying on each group mean is too reckless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways to handle this. A popular way is to use cross-validation and compute the means in each out-of-fold dataset. This is what what many Kagglers do.\n",
    "\n",
    "\n",
    "Another approach which I much prefer is to use is **additive smoothing.** This is supposedly what **IMDB uses to rate it’s movies.**\n",
    "\n",
    "The intuition is as follows. Imagine a new movie is posted on IMDB and it receives three ratings. Taking into account the three ratings gives the movie an average of 9.5. This is surprising because most movies tend to hover around 7, and the very good ones rarely go above 8. The point is that these first three ratings are extreme values that can’t been trusted. The trick is to “smooth” the average by including the average rating over all movies. In other words, if there aren’t many ratings we should rely on the global average rating, whereas if there enough ratings then we can safely rely on the local average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically this is equivalent to:\n",
    "\n",
    "<tex>\\mu = \\frac{n \\times \\bar{x} + m \\times w}{n + m}<tex>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where\n",
    "\n",
    "- \\mu is the mean we’re trying to compute (the one that’s going to replace our categorical values)\n",
    "\n",
    "\n",
    "- n is the number of values you have\n",
    "\n",
    "\n",
    "- \\bar{x} is your estimated mean\n",
    "\n",
    "\n",
    "- m is the “weight” you want to assign to the overall mean\n",
    "\n",
    "\n",
    "- w is the overall mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notation m is the only parameter you have to set. The idea is that the higher m is, the more you’re going to rely on the overall mean w. If m is equal to 0 then you’re simply going to compute the empirical mean, which is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\mu = \\frac{n \\times \\bar{x} + 0 \\times w}{n + 0} = \\frac{n \\times \\bar{x}}{n} = \\bar{x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words you’re not doing any smoothing whatsoever.\n",
    "\n",
    "Again this is quite easy to do in Python. First we’re going to write a method that computes a smooth mean. It’s going to take as input a pandas.DataFrame, a categorical column name, the name of the target column, and a weight m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_smooth_mean(df, by, on, m):\n",
    "    # Compute the global mean\n",
    "    mean = df[on].mean()\n",
    "\n",
    "    # Compute the number of values and the mean of each group\n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "\n",
    "    # Compute the \"smoothed\" means\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "\n",
    "    # Replace each value by the according smoothed mean\n",
    "    return df[by].map(smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see what this does in the previous example with a weight of, say, 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_0'] = calc_smooth_mean(df, by='x_0', on='y', m=10)\n",
    "df['x_1'] = calc_smooth_mean(df, by='x_1', on='y', m=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_0       x_1  y\n",
       "0  0.6  0.526316  1\n",
       "1  0.6  0.526316  1\n",
       "2  0.6  0.526316  1\n",
       "3  0.6  0.526316  1\n",
       "4  0.6  0.526316  0\n",
       "5  0.4  0.526316  1\n",
       "6  0.4  0.526316  0\n",
       "7  0.4  0.526316  0\n",
       "8  0.4  0.526316  0\n",
       "9  0.4  0.454545  0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s should be quite noticeable that each computed value is much closer to the overall mean of 0.5. This is because a weight of 10 is rather large for a dataset of only 10 values. The value d of variable x_1 has been replaced with 0.454545 instead of the 0 we got earlier. The equation for obtaining it was:\n",
    "\n",
    "d = \\frac{1 \\times 0 + 10 \\times 0.5}{1 + 10} = \\frac{0 + 5}{11} \\simeq 0.454545\n",
    "\n",
    "\n",
    "Meanwhile the new value for replacing the value a of variable x_0 was:\n",
    "\n",
    "a = \\frac{5 \\times 0.8 + 10 \\times 0.5}{5 + 10} = \\frac{4 + 5}{15} = 0.6\n",
    "\n",
    "\n",
    "Computing smooth means can be done extremely quickly. What’s more you only have to choose a single parameter, which is m. I find that setting to something like 300 works well in most cases. It’s quite intuitive really: you’re saying that you require that there must be at least 300 values for the sample mean to overtake the global mean. There are other ways to do target encoding, you can google for one which is rather popular on Kaggle. However it produces encoded variables which are very correlated with the output of additive smoothing, at the cost of requiring two parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
